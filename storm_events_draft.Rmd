---
title: "Opportunities and challenges for the use of NOAA Storm
Events database for societal impacts research"
author:
- Therese Kondash
- Andrea Schumacher
- Brooke Anderson

abstract: |
  Severe weather events currently cause tens of thousands of deaths per year in the United States and cost trillions of dollars in damaged property and economic loss.  These weather events and their impacts are tracked and recorded by several organizations such as the National Weather Service (NWS), the National Oceanic and Atmospheric Administration (NOAA),  and the Federal Emergency Management Agency (FEMA).  This disaster data is used by scientists in several fields of study (economics, epidemiology, atmospheric science, agriculture, etc.) to examine how weather events impact human life and how we can reduce or avoid these impacts.  However, storing disaster data faces unique challenges because of the quickly evolving nature of recording processes and weather technology. These challenges pose concerns regarding biases and errors in disaster data.  This paper investigates the presence of mechanisms that could lead to biases in the NOAA Storm Events database. This database contains information on storms, significant weather phenomena, rare or unusual weather, and other significant meteorological events across the United States.  We use the noaastormevents package in R to examine evidence of bias within the Storm Events weather data and propose ways to avoid errors while using this data in future studies. This examination reveals five major categories of bias present in the Storm Events data set that are common in weather data. These five categories include hazard bias, temporal bias, threshold bias, accounting bias, and geographic bias. We suggest that these biases result from various factors including structural changes over time, reporting errors, inherent bias, and others.  Outlining these factors and understanding their impacts will help scientists use large amounts of data appropriately and portray new findings accurately.  
  
output:
  pdf_document: default
  word_document: default
  html_document: default
bibliography: scholar.bib
---
```{r warning = FALSE, message = FALSE}
library(noaastormevents)
library(tidyverse)
library(viridis)
library(lubridate)
library(dendextend)
library(kableExtra)
events_2019 <- create_storm_data(date_range = c("2019-01-01", "2019-12-31"))
```

# Introduction  

Severe weather events currently cost the US trillions of dollars, damage property and crops, interrupt commerce, and cause extensive human injury and fatality. Since 1980, the US has experienced 273 weather and climate disasters that each cost over $1 billion [@impacts]. Additively, these events cost the US over $1.790 trillion and caused 14,223 deaths [@impacts].  Scientists expect these outcomes to worsen over time as climate change causes weather events to occur more frequently and with more severity.  This is demonstrated by increasing concentrations of greenhouse gases in the atmosphere that have shown to lead to increasing annual and extreme temperatures.  These impacts and others will increase over time as climate change intensifies extreme temperatures and other dangerous weather events. Other weather events will also continue to impact human health and cause more damages in the US as a result of climate change. 

<!-- Extreme temperatures can lead to a wide range of health complications. Extreme heat can lead to heat cramps, heat exhaustion, heatstroke, and hyperthermia, while extreme cold leads to hypothermia and frostbite [@climatechange].Extreme temperatures also exacerbate health conditions related to cardiovascular disease, respiratory disease, cerebrovascular disease, and diabetes [@climatechange]. -->

Several organizations currently collect data in attempts to compile, categorize, and quantify weather events and their impacts. Some of these organizations include the National Oceanic and Atmospheric Administration (NOAA), the U.S. Geological Survey (USGS), and the Federal Emergency Management Agency (FEMA). Data collection by these organizations improves scientists' ability to predict weather events and outline monetary losses, property damage, etc.  These predictions are commonly accomplished with interdisciplinary research involving fields of study such as epidemiology, atmospheric science, agriculture, economics, etc. Continued interdisciplinary research is critical to help avoid such large fallout and loss from future weather events. 

As this research continues, it is incumbent that scientists understand the biases and limitations in weather datasets to use the large amount of data appropriately and portray new findings accurately. Biases and limitations arise in these datasets because storing disaster data is a challenging endeavor. Challenges arise as the process of recording disaster data and the technology we use to do it are constantly evolving.[would a sentence here about what this entails be helpful?] Gall et al. recognized this issue and wrote a paper covering several bias types associated with major disaster databases used in the US [@gall2009losses]. These biases include hazard bias, temporal bias, threshold bias, accounting bias, geography bias, and systemic bias [@gall2009losses]. 

One such weather database in which these biases arise is the National Oceanic and Atmospheric Administration's Storm Events database. This database was created in 1950 and is now maintained by branches of NOAA including the National Weather Service (NWS) and the National Center for Environmental Information (NCEI). It originally only contained information regarding tornado events, but has expanded to include data on 55 different storms, significant weather phenomena, rare/unusual weather, and other significant meteorological events across the United States. This data is saved in files categorized by year and published annually in the NOAA Storm Events Publication [link]. This expansive dataset is an important resource used by atmospheric scientists to analyze fatalities and other losses associated with weather events to complete scientific research [cite examples- using for other reasons].  The American Meteorological Society has published several papers that use this research to characterize specific weather events and identify unique vulnerabilities or behaviors that place humans in harm's way [@terti2017situation, @ashley2005derecho, @ashley2008fatalities, @gensini2010examination]. These studies help provide justification for improvements to weather warning systems or future risk assessments. 

In this paper, we will examine the NOAA Storm Events database and investigate the presence of mechanisms that lead to biases in the data. We outline these biases in five major categories of hazard bias, temporal bias, threshold bias, accounting bias, and geographic bias. The goal of this investigation is to improve the ease and accuracy of research using this data to study harmful impacts of weather events in the US.


### Examples of Storm Events being used in literature 


The American Meteorological Society has published various papers analyzing fatalities associated with weather events [@terti2017situation, @ashley2005derecho, @ashley2008fatalities, @gensini2010examination]. Ashley and Black examined the cause, spatial distributions, and fatalities caused by nonconvective high-wind events in the US from 1980 to 2005. This study found that fatalities associated with nonconvective high-wind events often occur in boats or vehicles. These fatalities are most likely to occur on the West Coast or Northeast as a result of extratropical cyclones. These areas of the US have large forests and bodies of water with high population densities that are opportune to being highly affected by high winds [@ashley2008fatalities]. Keeping these vulnerabilities in mind, the study outlines possible improvements to high wind warning systems in the areas. These improvements aim to protect people most likely to be injured or killed by nonconvective high-wind events.   

Ashley and Mote conducted a similar study examining derecho events in the US from 1986 to 2003 [@ashley2005derecho]. Derechoes are often overlooked when examining impactful weather events. However, this study revealed how they actually produce damage comparable to tornadoes and hurricanes. Derechoes caused 153 fatalities and over 2,600 injuries throughout the 18 year span of this study. They were also responsible for as much or more monetary loss than some hurricane and tornado events over the time span. Their study helps to draw attention to this type of weather event in hopes to advance derecho risk assessments.  

# Terminology and how the database works

Throughout this paper, we will be using specific terminology when describing the structure and function of the NOAA Storm Events database. We use the term hazard or weather event to refer to all of the possible event types that can be entered in the NOAA Storm Events database. A hazard can be defined as something that has the potential to cause damage or a threat that can severely disrupt society's workings. A hazard's potential to cause harm is compounded by human factors like culture, gender, race, socioeconomic status and political structure and by human activity like land development, urbanization, emergency preparedness, and response plans [cutter1996responses].  These factors can influence the actual potential for harm, the perceived potential for harm, and the ability to respond if a disaster does occur.  

The terms risk and disaster are two other concepts that tie into the definition of a hazard. Risk is the probability of a hazard occurring and actually causing harm. A disaster is the occurrence of a hazard that creates a large impact on a group of people or peoples. For example, a shark swimming in the ocean is a hazard that has potential to cause damage. However, the risk of this hazard causing a person harm varies depending on the person's location relative to the shark. This hazard would become a disaster if the shark attacked the swimmer. 

<!--Susan Cutter has done extensive research on hazards and has spent much time defining these different terms. In her work, she states that hazards include the probability of an event occurring (risk), the impact, and the contextual/socioeconomic elements surrounding it. Other scientific authors have similar thoughts on the term hazard and believe it is important to include human culpability [@mcentire2005revisiting].--> 

We use the term disaster to refer to a reported occurrence of a specific hazard. NOAA Storm Events currently records 55 different event types that are listed in the NWS instruction manual [@nwsinstruction]. Most of these event types correlate to one type of hazard but some of them correlate to different intensities  of the same type of hazard. Some examples of this include the event type "Strong Wind" versus "High Wind" or "Cold/Wind Chill" versus "Extreme Cold/Wind Chill". In these instances, the hazard would be wind or wind chill while the intensities are strong, high, cold, or extreme cold. 

For 2019, the database reported 51 total events of 55 different event types. The most frequent type of events reported were Thunderstorm Wind, which had over twice as many reports as the second most frequent, Hail. Hail, in turn, had almost twice as many events reported as the next most common few---Flood, Flash Flood, and Winter Weather. The least common reported events included Volcanic Ashfall, Sleet, Dense Smoke, Sneakerwave, Seiche, and Marine Tropical Depression.

[TK: include plot of event types in 2019]

```{r echo = FALSE, message = FALSE}
events_2019 %>%
  group_by(EVENT_TYPE) %>%
  summarize(N = n()) %>%
  arrange(desc(N)) %>%
  mutate(N = prettyNum(N, big.mark = ",")) %>%
  knitr::kable(col.names = c("Event type", "Number of events in 2019"))
```

NOAA further characterizes its data by categorizing large storms as episodes which contain several individual events. NOAA assigns the disaster with one episode ID and its associated events with event IDs. Further details of the episode and events are recorded under the event narrative and episode narrative. The NWS instruction describes an episode as a swath of events occurring along a path from Point A to Point B during Time C to Time D [@nwsinstruction]. Events belonging to the same episode cannot be more than five calendar days apart to ensure they all resulted from one meteorological episode. This categorization helps to ensure that a single storm is not interpreted as a series of unrelated events. An example of this would be a hurricane given one episode ID, and the rain, wind, floods, etc. associated with that hurricane given event IDs that fall under that episode. 

To showcase this idea, for the episodes with the most events in 2019, the following graph shows the number of events reported for the episode. This figure demonstrates how one large weather episode can include several other events types. For example, one episode in this figure corresponds to an atmospheric river and cold front near Mount Saint Helena and indicates several reports of flood, debris flow, strong winds, high wind, and hail. All of these different event types occurred as a result of one large storm labelled episode 133801. This unique episode ID helps related events from getting double counted as separate entities.

[TK: include plot and add in names of episode in paragraph rather than numbers]
```{r eval = FALSE, echo = FALSE}
z_events_2019 %>% 
  filter(cz_type == "Z") %>% 
  select(cz_name, state, fips) %>% 
  mutate(cz_name = str_to_title(cz_name)) %>% 
  filter(str_detect(cz_name, "Lake") & !is.na(fips))  %>% 
  distinct()
```

```{r echo = FALSE, warning = FALSE}
z_events_2019 <- events_2019 %>%
  dplyr::select_(~ BEGIN_YEARMONTH, ~ BEGIN_DAY, ~ END_YEARMONTH, ~ END_DAY,
                   ~ EPISODE_ID, ~EVENT_ID, ~ STATE, ~ CZ_TYPE, ~ CZ_NAME,
                    ~ DEATHS_DIRECT, ~ DEATHS_INDIRECT, ~ INJURIES_DIRECT,
                  ~ INJURIES_INDIRECT, ~ DAMAGE_PROPERTY, ~ DAMAGE_CROPS,
                   ~ EVENT_TYPE, ~ STATE_FIPS, ~ CZ_FIPS, ~ SOURCE,
                   ~ EPISODE_NARRATIVE, ~ EVENT_NARRATIVE) %>%
  setNames(tolower(names(.))) %>%
  dplyr::filter_(~ cz_type == "Z") %>%
  match_forecast_county()
```

```{r echo = FALSE, warning = FALSE}
c_events_2019 <- events_2019 %>%
  dplyr::select_(~ BEGIN_YEARMONTH, ~ BEGIN_DAY, ~ END_YEARMONTH, ~ END_DAY,
                   ~ EPISODE_ID, ~EVENT_ID, ~ STATE, ~ CZ_TYPE, ~ CZ_NAME,
                  ~ DEATHS_DIRECT, ~ DEATHS_INDIRECT, ~ INJURIES_DIRECT,
                  ~ INJURIES_INDIRECT, ~ DAMAGE_PROPERTY, ~ DAMAGE_CROPS,
                   ~ EVENT_TYPE, ~ STATE_FIPS, ~ CZ_FIPS, ~ SOURCE,
                   ~ EPISODE_NARRATIVE, ~ EVENT_NARRATIVE) %>%
  setNames(tolower(names(.))) %>%
  dplyr::filter_(~ cz_type == "C") %>%
  dplyr::mutate_(fips = ~ as.numeric(paste0(state_fips, str_pad(cz_fips, 3, pad = "0"))))

county_events_2019 <- bind_rows(c_events_2019, filter(z_events_2019, !is.na(fips)))
```

```{r echo = FALSE, warning = FALSE}
county_damage_2019 <- county_events_2019 %>%
  dplyr::select(episode_id , event_id, fips, event_type, contains("damage")) %>% 
  tidyr::gather(key = impact, value = amount, -event_type, -event_id, -episode_id, -fips) %>%
  dplyr::mutate(amount = parse_damage(amount)) 
```

```{r echo = FALSE, warning = FALSE, eval = FALSE}
county_events_2019 %>%
  filter(episode_id == "99142" & fips == 2023) %>%
  select(event_type, contains("damage"), cz_name, state, event_narrative, episode_narrative) %>% 
  as.data.frame() %>% 
  pander::pander()
```

```{r echo = FALSE, warning = FALSE, fig.align = "center", fig.width = 6, fig.height = 4}
top_episodes <- events_2019 %>%
  group_by(EPISODE_ID) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>%
  slice(1:12)

a <- events_2019 %>%
  filter(EPISODE_ID %in% top_episodes$EPISODE_ID) %>%
  group_by(EPISODE_ID, EVENT_TYPE) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  spread(key = EPISODE_ID, value = n, fill = 0) %>%
  tibble::remove_rownames() %>%
  as.data.frame() %>%
  tibble::column_to_rownames(var = "EVENT_TYPE") %>%
  dist("canberra") %>%
  hclust() 
```

```{r echo = FALSE, fig.align = "center", fig.width = 8, fig.height = 6, message = FALSE}
dendrogram_descriptions <- tribble(
  ~EPISODE_ID, ~description,
  133275, "Moderate to strong atmospheric river in California",
  133801, "An atmospheric river and cold front near Mount Saint Helena",
  133994,"An atmospheric river in the North Bay",
  136054,"Several severe storms along southern plains",
  135416, "Squall line of thunderstorms in South Carolina",
  138800,"Heat wave in eastern New York",
  135253,"971mb bomb cyclone moving out of the Rockies", 
  138645,"Frontal boundary over the mid-Atlantic and
  low pressure wave",
  135643,"Line of thunderstorms",
  141710,"Strong cold front and deep upper level trough in the Ozarks",
  137355, "Multiple storms over Missouri Ozarks",
  142499,"A powerful coastal storm along New Jersey to the Northeast"
)


dedrogram_events <-events_2019 %>% 
  left_join(dendrogram_descriptions)

events_2019 %>%
  filter(EPISODE_ID %in% top_episodes$EPISODE_ID) %>%
  group_by(EPISODE_ID, EVENT_TYPE) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  left_join(dendrogram_descriptions, by = "EPISODE_ID") %>% 
  mutate(description = factor(str_wrap(description, width = 35, indent = 0)),
         description = fct_reorder(description, n, .fun = sum),
         EVENT_TYPE = factor(EVENT_TYPE, levels = unique(a$labels[a$order]))) %>%
  ggplot(aes(x = description , y = EVENT_TYPE)) + 
  geom_tile(aes(fill = n)) + 
  theme_classic() + 
  labs(x = "", y = "", fill = "Number of events reported") + 
  theme(axis.text.x  = element_text(angle=45, vjust = 1, hjust = 0),
        legend.position = "top",
        plot.margin = unit(c(0, 1, 0, 0), "cm"),
        axis.text=element_text(size=9)) +
  scale_x_discrete(position = "top") +
  scale_y_discrete(position = "right") +
  scale_fill_viridis(option = "A", direction = -1) +
  coord_flip() 

 # scale_x_discrete(limits = rev(levels(unique(top_episodes$EPISODE_ID)))) 
# scale_x_discrete(trans= "reverse")
```      

In some cases, events falling under one episode are the same type of hazard just at different intensities, as described above. In these circumstances, the collection of events may be recorded in only one county/zone but will showcase the spatial range and and varying intensity of the event. This is likely why we see the events with different intensities of the same hazard clustered together in one county/zone in the database, like heat/excessive heat and cold/extreme cold. In other cases, a larger synoptic weather system might bring a variety of different hazards leading to several different recorded event types (e.g., thunderstorm wind and hail, which cluster together). In these cases, there may be several counties/zones in the affected area that report more than one event for the episode. 

[TK: potentially add in map of events over different counties vs one county]

The following plot shows a cluster analysis to group events that are more likely to (be recorded as occurring) occur together within an episode. We removed event types with less that 50 listings in 2019. The figure shows that there are certain event types which are very commonly reported together such as high wind and strong wind or heat and excessive heat. These types of events are likely to be reported together because they are likely to occur at the same time. It is important to keep these trends in mind as there may be overlap or uncertainty in how to categorize what happened during an episode.

```{r echo = FALSE, fig.align = "center", fig.width = 6, fig.height = 10, warningv= FALSE}
b <- events_2019 %>%
  group_by(EVENT_TYPE) %>%
  mutate(n_events = n()) %>%
  ungroup() %>%
  filter(n_events >= 50) %>%
  group_by(EPISODE_ID, EVENT_TYPE) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  spread(key = EPISODE_ID, value = n, fill = 0) %>%
  tibble::remove_rownames() %>%
  as.data.frame() %>%
  tibble::column_to_rownames(var = "EVENT_TYPE") %>%
  dist("canberra") %>%
  hclust() 

dend<- as.dendrogram(b, hang = 0.3)%>% 
  set("leaves_pch", 19) %>% 
  set("leaves_col", "green") %>% 
  set("nodes_cex", 0.7) %>%
  set("branches_k_color", value = c("black", "skyblue", "orange", "black", "black", "blue","red", "hot pink", "purple", "black", "black", "brown", "black", "skyblue"), k = 14) 

dend %>% 
  plot(horiz=TRUE, axes=FALSE, main = "Event Type Cluster Analysis", col.main = "dark green") 

#plot(dend)
#rect.dendrogram(dend,
 # k = 3,
 # border = 8, lty = 5, lwd = 2
#)


```


# Hazard Bias  

In this section, we will outline how hazard bias may be created when using the NOAA Storm Events database for societal impacts research. Hazard bias can present itself as the probability of an event being recorded varying according to event type or the quality/quantity of information recorded varying according to event type. This can manifest in certain event types being under or over-reported in the dataset or having much more reliable and helpful descriptions of certain event types. This occurs because of variety of factors relating to how the database functions and how weather monitoring occurs. 


**Hazard bias by standards for when different events are recorded** 

[TK: this is just one mechanism for why this is going on ]

One mechanism that creates the opportunity for hazard bias arises out of the standards that the NOAA Storm Events database uses in deciding whether or not to include a disaster report in its dataset. The NWS Documetation record all standards used in making this decision here [link].  It appears that these standards vary based on event type. In general, the documentation states that the Storm Events database seeks to record rare, unusual, recording breaking, or highly impactful weather events. This implies that the database generally does not seek to record every event that is occuring, but rather focuses on events that are unusual (snow in Florida, record-breaking events) and/or things that impact humans (loss of life, property damage). However, the documentation goes on to state that "significant events" like Tornado events should always be recorded, regardless of if they had any impact like injury, fatality, or damage [@nwsinstruction]. Another example occurs  in that the NOAA documentation states that avalanches should only be recorded if human fatality or injury occurs. However, there are many types of avalanches (slab, loose snow, icefall, cornice fall, etc.) that can occur naturally due to a variety of environmental conditions which may not cause any human fatality or injury.  These variations have the potential to create hazard bias in the database by impacting the probability of an event being recorded given that it actually happened. This probability will be high for tornado events, because the database seeks to record all tornado events regardless of their impact. This probability will be low for avalanches because the database only seeks to record impactful occurences.

To avoid this bias in a study using data from Storm Events, it is important to match the intent of a research study with the intent of the databbase for the event type at hand. Your results could vary based on if you want to examine all occurences of a certain hazard type in a meteorological sense versus if you just want to examine their human impacts. If you are trying to catch every physical instace of a hazard type, this may not even be the goal of the database itself. We have organized the hazard types into general categories based on the NWS's standard for recording. 


[TK: include table that lists all events and if they recorded based on impact, or on intensity at the end of this section]

[TK: other examples: 
Drought hazards exemplify this issue; they are notoriously under-reported because there is a lack of physical damage and it is hard to quantify spatial and monetary losses (Gall, Borden, and Cutter 2009).

```{r echo= FALSE, message = FALSE}
event_reporting_areas <- tribble(
  ~ event_type, ~ reporting_area,
  "Astronomical Low Tide", "Forecast Zone", 
  "Avalanche", "Forecast Zone", 
  "Blizzard", "Forecast Zone",
  "Coastal Flood", "Forecast Zone",
  "Cold/Wind Chill", "Forecast Zone", 
  "Debris Flow", "County",
  "Dense Fog", "Forecast Zone", 
  "Dense Smoke", "Forecast Zone",
  "Drought", "Forecast Zone",
  "Dust Devil", "County",
  "Dust Storm", "Forecast Zone",
  "Excessive Heat", "Forecast Zone",
  "Extreme Cold/Wind Chill", "Forecast Zone",
  "Flash Flood", "County",
  "Flood", "County",
  "Freezing Fog", "Forecast Zone",
  "Frost/Freeze", "Forecast Zone",
  "Funnel Cloud", "County",
  "Hail", "County",
  "Heat", "Forecast Zone",
  "Heavy Rain", "County",
  "Heavy Snow", "Forecast Zone",
  "High Surf", "Forecast Zone",
  "High Wind", "Forecast Zone",
  "Hurricane/Typhoon", "Forecast Zone",
  "Ice Storm", "Forecast Zone",
  "Lakeshore Flood", "Forecast Zone",
  "Lake-Effect Snow", "Forecast Zone",
  "Lightning", "County",
  "Marine Dense Fog", "Marine Zone",
  "Marine Hail", "Marine Zone",
  "Marine Heavy Freezing Spray", "Marine Zone",
  "Marine High Wind", "Marine Zone", 
  "Marine Hurricane/Typhoon", "Marine Zone", 
  "Marine Lightning", "Marine Zone", 
  "Marine Strong Wind", "Marine Zone", 
  "Marine Thunderstorm Wind", "Marine Zone", 
  "Marine Tropical Depression", "Marine Zone", 
  "Marine Tropical Storm", "Marine Zone", 
  "Rip Current", "Forecast Zone", 
  "Seiche", "Forecast Zone", 
  "Sleet", "Forecast Zone",
  "Sneaker Wave", "Forecast Zone", 
  "Storm Surge/Tide", "Forecast Zone", 
  "Strong Wind", "Forecast Zone", 
  "Thunderstorm Wind", "County", 
  "Tornado", "County", 
  "Tropical Depression", "Forecast Zone", 
  "Tropical Storm", "Forecast Zone", 
  "Tsunami", "Forecast Zone", 
  "Volcanic Ash", "Forecast Zone", 
  "Waterspout", "Marine Zone", 
  "Wildfire", "Forecast Zone", 
  "Winter Storm", "Forecast Zone", 
  "Winter Weather", "Forecast Zone"
)



event_type_2019 <-events_2019 %>%
  mutate(EVENT_TYPE = case_when(
    EVENT_TYPE == "Sneakerwave" ~ "Sneaker Wave", 
    EVENT_TYPE == "Hurricane" ~ "Hurricane/Typhoon",
    EVENT_TYPE == "Volcanic Ashfall" ~ "Volcanic Ash",
    TRUE ~ EVENT_TYPE
  )) %>% 
  rename(event_type = EVENT_TYPE) %>% 
  group_by(event_type) %>%
  summarize(N = n()) %>%
  arrange(desc(N))



reporting_categories <- tribble(
  ~ event_type, ~ reporting_standard, 
  "Astronomical low tide", "impact, noteworthiness, public interest", 
  "Avalanche" , "impact, noteworthiness, public interest",  
  "Coastal Flood ", "impact, noteworthiness, public interest" ,
  "  Dense Fog ", "impact, noteworthiness, public interest" ,
  "Dense Smoke ", "impact, noteworthiness, public interest" ,
  "Dust Devil ", "impact, noteworthiness, public interest" ,
  "Dust Storm ","impact, noteworthiness, public interest",
  "Flash Flood", "impact, noteworthiness, public interest",
  "Flood", "impact, noteworthiness, public interest" ,
  "Freezing Fog", "impact, noteworthiness, public interest" , 
  "Funnel Cloud" , "impact, noteworthiness, public interest" ,
  "Freezing Fog" , "impact, noteworthiness, public interest" ,
  "Funnel Cloud" , "impact, noteworthiness, public interest" ,
  "Heavy Rain" , "impact, noteworthiness, public interest" ,
  "High Surf" , "impact, noteworthiness, public interest" , 
  "Lakeshore Flood" , "impact, noteworthiness, public interest" ,
  "Lightning" , "impact, noteworthiness, public interest" ,
  "Marine Dense Fog" , "impact, noteworthiness, public interest" ,
  "Marine Hail" , "impact, noteworthiness, public interest" ,
  "Marine Heavy Freezing Spray" , "impact, noteworthiness, public interest" ,
  "Marine High Wind" , "impact, noteworthiness, public interest" ,
  "Marine Hurricane/Typhoon","impact, noteworthiness, public interest" , 
  "Marine Lightning" , "impact, noteworthiness, public interest" ,
  "Marine Strong Wind" , "impact, noteworthiness, public interest" ,
  "Marine Thunderstorm Wind" , "impact, noteworthiness, public interest" ,
  "Marine Tropical Depression" , "impact, noteworthiness, public interest" ,
  "Marine Tropical Storm" , "impact, noteworthiness, public interest" ,
  "Rip Currents" , "impact, noteworthiness, public interest" ,
  "Seiche" , "impact, noteworthiness, public interest" ,
  "Sneaker Wave" , "impact, noteworthiness, public interest" ,
  "Storm Surge/Time" , "impact, noteworthiness, public interest", 
  "Strong Wind ", "impact, noteworthiness, public interest" , 
  "Thunderstorm Wind" , "impact, noteworthiness, public interest" ,
  "Tsunami" , "impact, noteworthiness, public interest" ,
  "Volcanic Ash" , "impact, noteworthiness, public interest" ,
  "Wildfire" , "impact, noteworthiness, public interest" ,
  "Winter Weather" , "impact, noteworthiness, public interest",
  "Blizzard", "intensity",
  "Cold/Wind Chill ", "intensity",
  "Debris Flow", "intensity",
  "Excessive Heat", "intensity",
  "Extreme Cold/Wind Chill", "intensity",
  "Frost", "intensity",
  "Hail", "intensity",
  "Heat", "intensity",
  "Heavy Snow", "intensity",
  "High Wind ", "intensity",
  "Hurricnae/Typhoon", "intensity",
  "Ice Storm", "intensity",
  "Lake Effect Snow", "intensity",
  "Sleet", "intensity",
  "Tornado", "intensity",
  "Tropical Depression", "intensity",
  "Tropical Storm", "intensity",
  "Waterspout", "intensity",
  "Winter Storm", "intensity"
)



event_type_2019 %>%
  full_join(event_reporting_areas) %>% 
  full_join(reporting_categories) %>% 
  arrange(desc(N)) %>%
  mutate(N = case_when(
    is.na(N) ~ as.integer(0), 
    TRUE ~ N 
  )) %>% 
  mutate(N = prettyNum(N, big.mark = ",")) %>%
  knitr::kable(col.names = c("Event type", "Number of events in 2019", "Reporting Area", 
                             "Reporting Standard"))


```


**By Varying Amounts of Information Provided** 

There are also instances where different amounts of information are available for different types of hazards listed in the database. The Storm data dataset has around 51 columnns of information per entry that include information like the event ID, time, state, county, damage, textual descriptions, etc. Not every one of these columns is filled with each entry in the database. 

*Narratives*  

This variation in the amount of information shows up in the textual descriptions provided per entry. For some types of reporting, the *episode* gets the narrative, but not separate narratives for each event, while for some events (like tornadoes), each *event* might get a narrative. The NWS Documentation covers this in section 2.9 Textual Description of Storm [link?]. The basic requirement is that each disaster [TK: questionable terminology here] entry within the Storm Data dataset recieves a short episode narrative. In addition to this, an event narrative should be entered if the event caused some sort of injury or damage, or something else significant. The documentation also states that an event narrative is requried for all Tornado events, all Thunderstorm Wind events, and all Lightning events, whether over land or marine zones. For these hazard types, the event may not have caused significant damage, but an event narrative will be still be present.  Other than this, if there is nothing noteworthy about the event itself, no event narrative is required. The documentation provides Hail events as an example because as a single phenomenon, Hail events do not need narratives unless they are part of a more complex weather episode or cause fatality/injury or property/crop damage [@nwsinstruction]. This is important to keep in mind because the presence of an event narrative does not necessarily indicate significance if it is for the hazard types where an event narrative is required. 

*Spatial Data*  

Similar variation occurs in the spatial data provided per hazard type. The NWS states that a hydrometereorological event should be referenced to the nearest hudredth of a mile, to the geographical center of a particular village, city, airport, inland lake, or location provided that the reference point is in the Storm Data software location database [@nwsinstruction]. The Storm Data preparer is also "strongly encouraged" to enter latitude/longitude to describe the location. 

Additionally, all event types are categorized into a county/parish (`CZTYPE` of "C"), a forecast zone (`CZTYPE` of "Z"), or a marine zone (`CZTYPE` of "M") (see table below)** [TK: referencing table with all event types, could also create a table exmaining an event that crossed several counties or forecast zones]. Forecast zones are created as subsets of counties for more specific location data. Specific types of events are typically either always reported for a county or always reported for a forecast zone. Events typically reported by county include floods, tornado-like events, and a few other events often related to thunderstorms. Events typically reported by forecast zone include severe winter weather, extreme heat, events related to the water or coast, and a few others ("High Wind", "Dense Fog", "Strong Wind", "Wildfire", "Dust Storm", "Dense Smoke"). 

This demonstrates the difficulty of narrowing down where exactly certain events occurred. Some events might be very localized (for example, a flash flood, or even storm surge that's only near the coast of the county), but the county-level reporting of the event means that the whole county gets classified as experiencing or not experiencing the event. For these localized events, the researcher may need to pay closer attention to the reference point or latitude/logitude data.

For all tornado events, the database also includes path length (in miles and tenths of miles) and width (in yards). This information is given in the header strip of the Storm Event publication per episode/event and it indicates the length of one segment in one county. A user of the Storm Data database can determine the entrie length of a multi-segmented tornado by adding the lengths of each segment or using latitude/longitude information. The documentation includes more stipulations on this topic in that the given path length will exclude sections without "surface damage/disturbance, unless other evidence of the touchdown (e.g., a trained spotter report, videotape of the tornado over a plowed field) is available" [@nwsinstruction]. This excluded section cannot exceed 2 continuous miles or 4 consecutive minutes of travel time or else it will be categorized as separate tornado events within the episode. 

Once again it appears that tornado events get a higher level of detailed information than other event types. This variation should be kept in mind when using this database to examine multiple hazard types.

[TK: documentation information from section 2.4 and 47.7. I can't find which events get latitude/lognitude data, I think it just can be entered if the preparer has that info?]


*Estimates of Damage (Monetary and Injury/Fatality)*

Another mechanism that creates the opportunity for hazard bias has to do with how monetary damage estimates are created for the database. The NWS documentation has this description for how damages should be recorded:  

> 2.7 Damage. Property damage estimates should be entered as actual dollar amounts, if a reasonably accurate estimate from an insurance company or other qualified individual is available. If this estimate is not available, then the preparer has two choices: either check the “no information available” box, or make an estimate. The lone exception is for flood events. The Storm Data preparer enters monetary damage amounts for flood events, even if it is an estimate. The U.S. Army Corps of Engineers requires the NWS to provide monetary damage amounts (property and/or crop) resulting from any flood event."

In a general sense, this could lead to bias if a researcher was trying to examine overall monetary damage across all event types because there is large variation in how this number is obtained. More specifically, estimates from insurance companies are probably more likely to be available for events that are highly impactful in larger cities. For example, hurricanes or tornadoes that pass through large cities would attract the attention of insurance companies that insure high concentrations of buildings and properties there. This may produce clearer records of damages than a smaller weather event that occurs in rural area. Additionally, the documentation points out that estimates for flood damage are required. This places higher importance on the amount of information recorded for one specific event type. Once again, this should be kept in mind if using this database for analysis of weather event related damages. 


[TK: ask Andrea about the above claim? ask James Done?]

[TK: I don't know if the following information belongs in the hazard bias section but I think it is important to point out in terms of varying levels of detail in event vs episode nanrratives]

For injury and fatality information, the database includes information on direct, indirect, and delayed injuries/fatalities. [TK: I could explain how the database distinguishes between these here, or just reference and/or link the documentation section] When a direct injury or fatality occurs from a weather event, it gets entered into the Storm Data's "fatality" and "injury" fields. When an indirect fatality or injury occurs, this information is included in the event narrative. Delayed fatalities are included in the original weather event entry with the actual date of fatality in the fatality enntry field. The documentation further states that Aan explanation can be given in the *episode* narrative for *zone-based* events, or in the *event* narrative for *county-based* or *marine zone-based* events.


### Hazard bias by who reported event 

Hazard bias may also arise from the variation in source type per hazard type. There is a wide range of people and detection devices that collect data for this dataset which may impact the probabilty of an event being recorded and the quality of information that is provided for a reported event. We have categorized the types of event sources for this database into four main categories: automated observation systems, officials or emergency response/agency, trained volunteers, and company or general public (see table below). This brings up several potential challenges. 

The likelihood of catching an event varies based on source because of different levels of detection technology. We may have a better process for ID-ing cases of one hazard type compared to another in that some are recorded with detection technology and some are reported by eye-witnesses. Events that are typically recorded by automated observation systems may be more likely to be reported than ones that are typically reported by the public. For example, an automated system would probably "see" any event that happens where the monitor is located, while an event that's usually reported by the public would miss anything that happens when a person isn't around or can't see it (e.g., at night, in a sparsely populated area). This can be seen in that sneakerwaves (also seiche, sleet) are rarely reported in the dataset and are only reported by sources like  broadcast media, fire department/rescue, and newspaper. [TK: do comparison of # of entries for an event type vs its source) 

Even within one type of source, that there may be controversy in the agreement across reports for a hazard entry.  There could be variation amongst the monitoring equipment for automated observation systems due to random error or inconsistent calibration. There could also be variation amongst people's opinions across volunteer reports especially if event criterias are unclear. Along these same lines, the quality of information provided in these accounts can vary based on if there is an established scale or not. For example, the Enhanced Fujita scale is the accepted way to rank and characterize tornado events. This scale provides a standard for explaing the intensity and impact of tornado events, whereas less common events do not have a widely accepted scale for description. These factors will impact how cohesive the information is for individual hazard entries and for collective hazard types. 

```{r echo = FALSE}
events_2019 %>%
  group_by(SOURCE) %>%
  summarize(N = n()) %>%
  arrange(desc(N)) %>%
  mutate(N = prettyNum(N, big.mark = ",")) %>%
  knitr::kable(col.names = c("Source of event report", "Number of events reported in 2019"))
```

[TK: include figure with # of events reported by event source in 2019, figure showing which sources typically report which event types, maybe table that lists sources into these four categories]
[BA: One may be that the (this is a similar idea to how changes in technology over time might lead to temporal bias). I wonder if some of our rare events (Sneakerwave, Seiche, Sleet) might be examples of spots where we don't have great technology yet to detect them (or not a large enough network of monitors even if we do have the technology)?
Another point on this idea of different amount/quality of information on 
different hazards might be that some hazards are recorded based on clear ways to measure
intensity (for example, using a well-defined scale, as is done for tornadoes with the Fujita
scale), while others don't. The NOAA guidebook might have some details on this in terms of 
telling people to use specific scales to report some types of events. ]

[From Andrea: One note in terms of time-variability of tornado reporting - it's thought that that detection of weaker tornadoes (EF-1) has improved significantly in the last few decades (due to increases in population and better observation networks).  For that reason, researchers sometimes remove EF-1's when analyzing tornado trends to try to reduce this type of bias.  ]


### implications and discussion

[TK: I have woven the answer to some of these questions in the above parapraphs. Do you have ideas for what else we should expand on here? ]

For example, would it only be an issue when comparing frequencies of different types of events? Could it lead to confounding in a single-hazard study that's looking at disaster impacts? It would certainly result in undercounts of certain types of hazards, if you're trying to characterize how frequently a type of hazard tends to happen. Would there be implications from information bias, particularly measurement error? (We could save this paragraph to draft for after we've drafted the rest of this section, and just put in a placeholder for now.)

[TK: These were health implications of weather events that I omitted from the introduction]
In specific, scientists expect the number of naturally occurring wildfires to increase [@climatechange]. Wildfires emit particulate matter and ozone precursors which decrease air quality. Low air quality harms the human respiratory and cardiovascular systems and decreases overall well being and productivity.

Climate change is also projected to increase the number and severity of extreme natural disasters. Natural disasters threaten physical and mental health resulting from "damage to property, destruction of assets, loss of infrastructure and public services, social and economic impacts, environmental degradation, and other factors" [@climatechange].  



# Temporal Bias  

### Introduction to Temporal Bias: 
Within the NOAA Storm Events database, there are comparable differences in event and loss recording over time. Temporal bias is helpful in describing and understanding these changes within the database. There are long term patterns of temporal bias that may be caused by changes in measuring and recording events and losses. There are also seasonal patterns within the database that relate to unique attributes and temporality of certain weather events.  


Main Points: 
1. database has changed what it records over time 
2. Population growth over time has changed where and how people there are to 
3. Technology changes over time 

### Long Term Trends: 
Long term temporal bias arises because technology is getting better at detecting storm events, population size is growing in high hazard areas, and the NWS has changed their recording strategies and monetary loss acounting. 

Scientists have improved radar and expanded networks of monitors and so they detect more extreme weather events. The advancement of doppler radar and dual-polarization radar technology has increased our ability to detect tornado events [@tornadodetection]. Forcasters and storm spotters have also discovered patterns that help them recognize tornado formation. These advancements increase the tornadoes detected. Verbout et. al states that "the number of tornadoes reported in the United States has doubled from about 600 per year in the 1950s to around 1200 in the 2000s"[@verbout2006evolution]. Technology increases this reported number rather than meteorological changes. 


Increasing population size and land development also contribute to increased event reporting over time. Population growth increases the probability that an event in an area gets reported. This is because events are reported to the NWS by trained spotters, the public, law enforcement, broadcast media, social media, local and county officials, etc. When the number of these individuals increases in an area, so does the likelihood that they will see and report an event. 


#### Breakdown of percentage of events reported by a given source: 


The following graph shows, for each type of event in 2019, the percent reported by each source. Both axes of the plot are ordered by overall frequency (i.e., overall number of each type of event and overall number of reports from each source).
 
For some types of events, reporting is dominated by a specific source. For example, most high surf reports come from trained spotters, while most drought reports come from drought monitors and most tornado reports come from the NWS Storm Survey. Another example is that rip currents are mostly reported by broadcast media and newspapers. This may be because rip currents can pose a serious danger to humans and cause death in certain instances. These instances are more likely to make the news than other types of general events. 

For other types of events, reporting sources are more diversified.

Additionally, certain sources are more influential in reporting certain events. For example, the public often reports hail and marine hail events. This may be because the public is usually highly affected by this type of weather event. 

### Seasonal Trends:

Although certain weather events truly exhibit seasonal differences in their meteorology, other factors related to temporal bias may artificially inflate or deflate the number of certain events recorded throughout the year. One of these factors is how the timing of a weather event's hazardous outcomes could attract more attention. The media and the public are more likely to report a weather event when it directly physically affects them. One example of this occurs with rip currents. NOAA exhibits higher rates of rip currents in the summer versus the winter. Gensini and Ashley also found that "summer season weekends are shown to have the most [rip current] fatalities than any other time of the year" [@gensini2010examination]. However, the probablity of a rip current occuring during summer or on the weekend may not be inherently higher. It may be that more people attend the beach and swim in the ocean during the summer and on the weekends and are thus more likely to experience and/or report a rip current. Humans experience the hazardous outcome more in the summer and thus will be more likely to report it during that time. 

* Seasonal Differences in number of events reported 

    - Example of rip currents in summer vs winter  
    
* Direct quote: The strength of rip currents can be seasonal. During hurricane season (from June to November) there is a greater chance for rip currents to develop.[@natgeo]
* Rip currents are related to several envrionmental factors including waves (surf heights, period, direction), beach (slope, orientation, material), water levels (tidal cycle, tide ranges), winds (affect wave breaking) and wind-driven currents alongshore, others like local coastal configuration and beach and promontories by natural or human made. [@nwsripcurrent]
* "The most likely scenario for rip hazards is not high surf but high exposure of beachgoers in the warm water of the summer-fall period. When low-energy, longer-period waves (significant wave heights of 0.5 -1.5 meters in 10-15 second sequences) lead to the highest number of rip incidents. During spring/neap tides or very low daily tidal cycles, a mass rescue event can occur, with hundreds of rescues in several locations on a beach, or at several beaches under the same conditions." [@nwsripcurrent]
* "societal factors (e.g., weekends and holidays) that could change the risk of a rip current fatality. For example, low and high pressure systems off the east coast of the United States can produce onshore flow to many surf zones. Both systems may invoke a high rip current formation risk on the LURCS, but swimmers will be more inclined to enter the water on days when a high pressure system is offshore. The clear skies generally associated with large-scale subsidence of a high pressure system would provide beachgoers with favorable weather for beach activities as opposed to a day amid a low pressure system with stratus clouds and precipitation occurring" [@gensini2010examination] 
       
        
* create table of number reported by lifeguards or media vs month of the year  
        
    - other events that are more or less reported? [BA: We might want to talk about the idea of some events that truly are seasonal in their occurrence, like avalanches and hurricanes, versus some that happen year-round but have varying chance of being reported. Also, you can look through the package vignette and see if you see any other examples of things that might not be reported evenly throughout the year.]   
    
    - coastal flood? high surf? waterspout?
    
[BA: I'm not sure if you saw it yet, but I added in another paper on rip currents that to the "literature" folder that might be another helpful reference for this section.]

#### How start dates for events are distributed over the year 

[I don't know if we've explained yet that events are listed with a start and end date. We
might want to explain that here.]
Here are how the start dates for listings for each event type are distributed over the year
(event types are ordered by decreasing total count during the year; note that the y-axes vary depending on the range of events by date for each event type): 

Many event types are clearly seasonal (e.g., winter weather, winter storms, heavy snow, cold, extreme cold, blizzards, ice storms, lake-effect snow, and avalanches are all much more common during winter months, while heat and extreme heat are typically limimted to summer months). However, for some events, reporting seasonal patterns might be based not just on the true pattern of events but also on the timing of important exposures and impacts of the events. For example, rip currents have many more listings during the spring and summer, which may be related to events being more likely to be listed when more people are swimming. Frost event listings are particularly high at the start and end of the frost season, rather than in the middle of winter, which may be related to the impacts of frost on crops being higher in spring and fall than during the winter. If working with this data, it important to keep in mind that the data are based on reporting, and there may be related influences on the probability of an event being reported and included in the data that differ from using data from something like a weather station.  

[BA: Could you check on Google Scholar and see if we could find out anything from the literature
to support our idea here that you're going to get frost through the winter, but that the 
most economically damaging frost comes near the edges of the frost season.]

 
# References  

